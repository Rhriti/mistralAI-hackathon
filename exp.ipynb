{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This story begins with an end. In March 1991, ...</td>\n",
       "      <td>5ee2fbb48ef35593b81444d7aec405bb4f152abbe80f7b...</td>\n",
       "      <td>[{'content': 'This story begins with an end. I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Explain how the invention and widespread use o...</td>\n",
       "      <td>fc6aae406cd26c79db4d35dd32bcbd8ee0f1493a0096b5...</td>\n",
       "      <td>[{'content': 'Explain how the invention and wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Read the passage below and answer the question...</td>\n",
       "      <td>44a13514d9cd363d85479ff25e5837c60c5f90815428c2...</td>\n",
       "      <td>[{'content': 'Read the passage below and answe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Explain the influence of culture on attitudes ...</td>\n",
       "      <td>c0c7f2a08bd4dc84bc527d774b1fe411eefa7bcdb847b5...</td>\n",
       "      <td>[{'content': 'Explain the influence of culture...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can you provide data on the employment rates i...</td>\n",
       "      <td>b26cb026578e891c3ccd0cf075da6cffaa05df05412aa0...</td>\n",
       "      <td>[{'content': 'Can you provide data on the empl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt   \n",
       "0  This story begins with an end. In March 1991, ...  \\\n",
       "1  Explain how the invention and widespread use o...   \n",
       "2  Read the passage below and answer the question...   \n",
       "3  Explain the influence of culture on attitudes ...   \n",
       "4  Can you provide data on the employment rates i...   \n",
       "\n",
       "                                           prompt_id   \n",
       "0  5ee2fbb48ef35593b81444d7aec405bb4f152abbe80f7b...  \\\n",
       "1  fc6aae406cd26c79db4d35dd32bcbd8ee0f1493a0096b5...   \n",
       "2  44a13514d9cd363d85479ff25e5837c60c5f90815428c2...   \n",
       "3  c0c7f2a08bd4dc84bc527d774b1fe411eefa7bcdb847b5...   \n",
       "4  b26cb026578e891c3ccd0cf075da6cffaa05df05412aa0...   \n",
       "\n",
       "                                            messages  \n",
       "0  [{'content': 'This story begins with an end. I...  \n",
       "1  [{'content': 'Explain how the invention and wi...  \n",
       "2  [{'content': 'Read the passage below and answe...  \n",
       "3  [{'content': 'Explain the influence of culture...  \n",
       "4  [{'content': 'Can you provide data on the empl...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('https://huggingface.co/datasets/HuggingFaceH4/ultrachat_200k/resolve/main/data/test_gen-00000-of-00001-3d4cd8309148a71f.parquet')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df.sample(frac=0.995,random_state=200)\n",
    "df_eval=df.drop(df_train.index)\n",
    "\n",
    "df_train.to_json(\"ultrachat_chunk_train.jsonl\", orient=\"records\", lines=True)\n",
    "df_eval.to_json(\"ultrachat_chunk_eval.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 3674th sample\n",
      "Skipped 9176th sample\n",
      "Skipped 10559th sample\n",
      "Skipped 13293th sample\n",
      "Skipped 13973th sample\n",
      "Skipped 15219th sample\n"
     ]
    }
   ],
   "source": [
    "# validate and reformat the training data\n",
    "! python reformat_data.py ultrachat_chunk_train.jsonl\n",
    "\n",
    "# validate the reformat the eval data \n",
    "! python reformat_data.py ultrachat_chunk_eval.jsonl"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 3,
>>>>>>> 8c5a0c230373b1c6b06989c44c686fe946c645b9
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mistralai.client import MistralClient\n",
    "\n",
    "api_key = os.getenv(\"mistral_api\")\n",
    "client = MistralClient(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 7,
>>>>>>> 8c5a0c230373b1c6b06989c44c686fe946c645b9
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from mistralai.client import MistralClient\n",
    "\n",
    "api_key = os.getenv(\"mistral_api\")\n",
    "client = MistralClient(api_key=api_key)\n",
    "\n",
    "with open(\"ultrachat_chunk_train.jsonl\", \"rb\") as f:\n",
    "    ultrachat_chunk_train = client.files.create(file=(\"ultrachat_chunk_train.jsonl\", f))\n",
    "with open(\"ultrachat_chunk_eval.jsonl\", \"rb\") as f:\n",
    "    ultrachat_chunk_eval = client.files.create(file=(\"ultrachat_chunk_eval.jsonl\", f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Job(id='d9636ac7-e365-4ac2-935e-0c30169f2082', hyperparameters=TrainingParameters(training_steps=10, learning_rate=0.0001), fine_tuned_model=None, model='open-mistral-7b', status='QUEUED', job_type='FT', created_at=1718816162, modified_at=1718816162, training_files=['6aea3309-15e4-4be7-9c35-a34eb401578e'], validation_files=['98e58d2b-b3f1-4d68-b28d-b8c25dc35f8a'], object='job', integrations=[])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mistralai.models.jobs import TrainingParameters\n",
    "\n",
    "created_jobs = client.jobs.create(\n",
    "    model=\"open-mistral-7b\",\n",
    "    training_files=[ultrachat_chunk_train.id],\n",
    "    validation_files=[ultrachat_chunk_eval.id],\n",
    "    hyperparameters=TrainingParameters(\n",
    "        training_steps=10,\n",
    "        learning_rate=0.0001,\n",
    "        )\n",
    ")\n",
    "created_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: SUCCESS\n"
     ]
    }
   ],
   "source": [
    "# Get the ID of the job you want to check\n",
    "jobid = created_jobs.id\n",
    "\n",
    "# Use the client.jobs.retrieve() method to retrieve information about the job\n",
    "job = client.jobs.retrieve(jobid)\n",
    "\n",
    "# Check the status of the job\n",
    "status = job.status\n",
    "print(f\"Job status: {status}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "retrieved_job = client.jobs.retrieve('d9636ac7-e365-4ac2-935e-0c30169f2082')\n",
    "print(retrieved_job.status)\n",
    "while retrieved_job.status in [\"RUNNING\", \"QUEUED\"]:\n",
    "    retrieved_job = client.jobs.retrieve('d9636ac7-e365-4ac2-935e-0c30169f2082')\n",
    "    print(retrieved_job)\n",
    "    print(f\"Job is {retrieved_job.status}, waiting 10 seconds\")\n",
    "    time.sleep(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data=[Job(id='d9636ac7-e365-4ac2-935e-0c30169f2082', hyperparameters=TrainingParameters(training_steps=10, learning_rate=0.0001), fine_tuned_model='ft:open-mistral-7b:1d868e37:20240619:d9636ac7', model='open-mistral-7b', status='SUCCESS', job_type='FT', created_at=1718816162, modified_at=1718816335, training_files=['6aea3309-15e4-4be7-9c35-a34eb401578e'], validation_files=['98e58d2b-b3f1-4d68-b28d-b8c25dc35f8a'], object='job', integrations=[])] object='list'\n"
     ]
    }
   ],
   "source": [
    "# List jobs\n",
    "jobs = client.jobs.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ChatCompletionResponseChoice(index=0, message=ChatMessage(role='assistant', content='The \"best\" French cheese is subjective and depends on personal preference. However, some of the most famous and well-loved French cheeses include Brie, Camembert, Roquefort, and Comt√©. These cheeses are known for their unique flavors, textures, and aromas that are often used in French cuisine.', name=None, tool_calls=None, tool_call_id=None), finish_reason=<FinishReason.stop: 'stop'>)]\n"
     ]
    }
   ],
   "source": [
    "from mistralai.models.chat_completion import ChatMessage\n",
    "\n",
    "chat_response = client.chat(\n",
    "    model=retrieved_job.fine_tuned_model,\n",
    "    messages=[ChatMessage(role='user', content='What is the best French cheese?')]\n",
    ")\n",
    "print(chat_response.choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
